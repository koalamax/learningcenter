# 컴퓨터는 2진수를 사용한다.
인간은 10진수(0~9)를 사용하고 9가 넘어가면 자리올림을 한다.
그렇다면 컴퓨터도 10진수를 사용하는가?
아니다. 컴퓨터는 전압 OFF/ON(5v)를 대표하는 0과1만 사용한다
0과1은 흡사 흑백논리를 만나는 기분이다.
옳고 그름
검정과 흰색
이것 아니면 저것
(이넘들은 그럼 중간이 없는가?)
그렇다면 어떻게 0과 1로 그 많은 모든수를 표현하는가?
그것은 바로 자릿수를 많이 이동하기 때문이다.

인간은 0~9까지는 1자리수로 표현을 할 수 있지만
컴퓨터는 0과1 까지는 1자리수지만 그다음 숫자 2부터는 자릿수를 변경한다.

예를들면, 아래와 같다.
10진수	2진수
0	    0000
1	    0001
2	    0010
3	    0011
4	    0100
5	    0101
6	    0110
7	    0111
8	    1000
9	    1001

자릿수는 컴퓨터에서는 비트라고 한다.
위의 예제에서 9를 표현할려면 최소한 4bit는 있어야 한다.

4bit로 표현할 수 있는 숫자의 범위는 2의 4승이다
즉! 0~15번까지 16개의 숫자를 표현할 수 있다

각 비트별로 자릿수를 대표하는 번호가 있는데 이른바 순차적으로 8 4 2 1 이다

2의3승, 2의2승, 2의1승, 2의0승

8421이라는것을 어떻게 사용하는가?
그건 간단하다.
예를들어 9를 표현할려면
8과1이 있으면 되므로
해당되는 각 자릿수를 1로 바꾸면 된다.
1001이 바로 직관적으로 나온다.

그러면 10은 어떻게?
8과 2가 있으면 되므로
1010이 직관적으로 나온다

그러면 16은 어떻게 표현하는가?
8421로는 표현을 하지 못한다
왜냐하면 1111 (8+4+2+1)=15밖에 나오질 않는다

16을 표현할려면 5비트가 필요하다.
10000이 바로 16인것이다.

그러면 더 8421을 확장한다면 아주 간단하다
2배씩 올리면 된다. 

... 1024 512 256 128 64 32 16 8 4 2 1 0.5 0.25 0.125 0.0625 ...

비트가 왼쪽으로 가면 2배씩 증가한다. 
반면에, 비트가 오른쪽으로 가면 2배씩 감소한다

이걸 이른바 "쉬프트연산"이라고 한다 (<<, >>)


그러면 내가 만약 256까지 표현하고 싶으면 몇 비트가 필요할까?
2의 8승 = 256이므로 8비트가 필요할것 같지만
0을 넣으면 0~255까지 표현할수 있는것이다.

즉! 256을 표현할려면 9비트가 필요하다.


그러면 아주 오래전에 애플컴퓨터가 최초 생산될때 8비트 컴퓨터로 출시됐는데 
그 컴퓨터는 0~255까지만 인식헸던것인가??

0~255 숫자로 어떻게 데이터를 처리했을까???

아. 모르겠다. chatgpt선생님께 물어봐야 겠다.

--- 아래는 chatgpt 선생님의 답변 ----
2. 8비트 컴퓨터에서 16비트 연산은 어떻게 했을까?
**8비트 CPU(예: MOS 6502, Zilog Z80)**는 8비트 레지스터만을 가지고 있었기 때문에, 한 번에 8비트까지만 처리할 수 있었습니다.
하지만, 큰 숫자를 다루기 위해 "다중 바이트 연산"을 사용했습니다.

예: 500(10진수) 더하기 100(10진수)
500 = 00000001 11110100 (2바이트)
100 = 00000000 01100100 (2바이트)
더하기 연산을 수행
하위 바이트 연산: 11110100 (244) + 01100100 (100) = 1 01101100 (오버플로 발생, 상위 바이트에 1 전달)
상위 바이트 연산: 00000001 + 00000000 + 1(올림) = 00000010
결과: 00000010 01101100 (600)
즉, 2바이트(16비트) 연산을 수행하기 위해, 8비트 CPU는 두 개의 연속된 연산을 수행해야 했습니다.

3. 8비트 컴퓨터에서 32비트 이상의 숫자는?
8비트 CPU에서도 소프트웨어적으로 32비트(4바이트), 64비트(8바이트) 숫자를 다룰 수 있었습니다.
하지만, 하드웨어적으로 8비트씩 나누어 연산해야 했기 때문에, 연산 속도가 느려지는 단점이 있었습니다.
예를 들어, Zilog Z80이나 MOS 6502 같은 8비트 프로세서는 16비트 연산을 지원했지만, 32비트 연산을 하려면 더 많은 추가 연산이 필요했습니다.

결론
단일 8비트 값(1바이트)으로는 256 이상의 숫자를 표현할 수 없음.
하지만, 2바이트(16비트) 이상을 사용하면 500 같은 숫자도 표현 가능.
8비트 CPU에서도 큰 숫자를 다룰 수 있도록 여러 개의 바이트를 조합하여 연산을 수행했음.
하지만 8비트 환경에서 큰 숫자를 계산하려면 연산 속도가 느려지는 단점이 있었음.

---- chatgpt 추가답변-----

8비트 컴퓨터는 기본적으로 한 번에 8비트(1바이트)만 처리할 수 있기 때문에, 큰 수를 표현하는 데 다양한 방법을 사용했습니다.

1. 멀티바이트 표현 (다중 바이트)
8비트 컴퓨터는 8비트(0255, 부호 포함 시 -128127)까지만 직접 표현할 수 있지만, 여러 개의 바이트를 조합해서 더 큰 숫자를 표현할 수 있습니다.

예를 들어, 2바이트(16비트)를 사용하면 065535(부호 포함 시 -3276832767)를 표현할 수 있습니다.

3바이트(24비트) → 0~16,777,215

4바이트(32비트) → 0~4,294,967,295

2. 부동소수점(Floating Point)
일부 8비트 시스템은 부동소수점 연산을 지원했습니다. 예를 들어, IEEE 754 부동소수점 표현법을 간략화한 4바이트(32비트) 부동소수점 형식을 사용하기도 했습니다.

숫자를 부호(S), 지수(E), 가수(M) 형태로 저장하여 더 넓은 범위를 표현할 수 있었습니다.

예: 1.23 × 10^5 같은 방식으로 큰 수를 표현.

3. BCD(Binary-Coded Decimal, 2진화 10진법)
일부 8비트 컴퓨터(예: 초기 전자계산기)는 BCD 방식을 사용하여 큰 수를 다뤘습니다.

각 4비트는 하나의 10진 숫자(0~9)를 저장하며, 여러 개의 4비트를 조합해서 큰 수를 표현할 수 있었습니다.

예: 1234를 8비트로 표현하면 0001 0010 0011 0100 (각 4비트가 10진수 1, 2, 3, 4)

4. 소프트웨어 기반 긴 정수 (Arbitrary Precision)
8비트 컴퓨터에서 큰 정수를 계산해야 할 경우, 여러 바이트를 연결하여 소프트웨어적으로 처리하는 방법이 사용되었습니다.

예: 8바이트(64비트) 정수를 저장하고 연산하는 방식.

5. 캐리(Carry)와 자리 올림을 이용한 연산
8비트 연산으로 다룰 수 있는 범위를 넘으면, 캐리 플래그(Carry Flag)를 활용하여 다음 바이트로 연산을 이어가는 방식이 사용되었습니다.

예를 들어, 16비트 덧셈을 수행할 때:

하위 8비트끼리 더함.

캐리가 발생하면 상위 8비트에 1을 더함.

예제 (8비트 시스템에서 16비트 덧셈)
assembly
복사
편집
  LDA LOW_BYTE_1   ; 첫 번째 숫자의 하위 바이트 로드
  ADC LOW_BYTE_2   ; 두 번째 숫자의 하위 바이트 더하기
  STA RESULT_LOW   ; 결과 저장

  LDA HIGH_BYTE_1  ; 첫 번째 숫자의 상위 바이트 로드
  ADC HIGH_BYTE_2  ; 두 번째 숫자의 상위 바이트 + 캐리 더하기
  STA RESULT_HIGH  ; 결과 저장
이 방식으로 여러 바이트를 연결해 큰 수를 처리할 수 있었습니다.

📌 결론
8비트 컴퓨터는 단순 8비트만 사용하지 않고, 필요에 따라 여러 개의 바이트를 묶어서 더 큰 수를 표현했습니다.

16비트, 32비트 등 여러 바이트를 조합

부동소수점(FP) 방식 사용

BCD 방식 활용

소프트웨어적으로 긴 정수 구현

캐리 플래그를 이용한 자리 올림 연산

이런 기법들을 활용해서 큰 수를 다루었어요!
